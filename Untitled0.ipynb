{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzhhVOqzPFBY",
        "outputId": "56c3d3d6-6410-4520-805e-d7bd6dc429e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'GroundingDINO' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/IDEA-Research/GroundingDINO.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd GroundingDINO/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGjOD2mgPOKN",
        "outputId": "b0f7f2a9-aeb2-447f-80fd-521d3ce9d20a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GroundingDINO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya7XtqKFPSKr",
        "outputId": "98f64e1d-182a-4e13-c744-134b32ca8d14"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/GroundingDINO\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from groundingdino==0.1.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from groundingdino==0.1.0) (0.20.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from groundingdino==0.1.0) (4.47.1)\n",
            "Collecting addict (from groundingdino==0.1.0)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting yapf (from groundingdino==0.1.0)\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from groundingdino==0.1.0) (1.0.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from groundingdino==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from groundingdino==0.1.0) (4.10.0.84)\n",
            "Collecting supervision>=0.22.0 (from groundingdino==0.1.0)\n",
            "  Downloading supervision-0.25.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from groundingdino==0.1.0) (2.0.8)\n",
            "Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from supervision>=0.22.0->groundingdino==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from supervision>=0.22.0->groundingdino==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from supervision>=0.22.0->groundingdino==0.1.0) (3.10.0)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.11/dist-packages (from supervision>=0.22.0->groundingdino==0.1.0) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from supervision>=0.22.0->groundingdino==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from supervision>=0.22.0->groundingdino==0.1.0) (2.32.3)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from supervision>=0.22.0->groundingdino==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.11/dist-packages (from supervision>=0.22.0->groundingdino==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm->groundingdino==0.1.0) (0.27.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->groundingdino==0.1.0) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->groundingdino==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->groundingdino==0.1.0) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->groundingdino==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->groundingdino==0.1.0) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->groundingdino==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->groundingdino==0.1.0) (0.21.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->groundingdino==0.1.0) (4.3.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision>=0.22.0->groundingdino==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision>=0.22.0->groundingdino==0.1.0) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision>=0.22.0->groundingdino==0.1.0) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision>=0.22.0->groundingdino==0.1.0) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6.0->supervision>=0.22.0->groundingdino==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision>=0.22.0->groundingdino==0.1.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision>=0.22.0->groundingdino==0.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision>=0.22.0->groundingdino==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->supervision>=0.22.0->groundingdino==0.1.0) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->groundingdino==0.1.0) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision>=0.22.0->groundingdino==0.1.0) (1.17.0)\n",
            "Downloading supervision-0.25.1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: addict, yapf, supervision, groundingdino\n",
            "  Running setup.py develop for groundingdino\n",
            "Successfully installed addict-2.4.0 groundingdino-0.1.0 supervision-0.25.1 yapf-0.43.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir weights"
      ],
      "metadata": {
        "id": "E1-ucG1vPX8z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd weights\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy20S0DcPaNZ",
        "outputId": "a8332643-4cb6-4d10-e9b5-4bd7a3a69f93"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GroundingDINO/weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n"
      ],
      "metadata": {
        "id": "7n2pe1vgPdWw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRZKn5taPfLs",
        "outputId": "a4d670a0-e251-4269-cd7d-d6553648cf79"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GroundingDINO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install diffusers transformers accelerate scipy safetensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0TRU7EVPge4",
        "outputId": "861b349b-4e4a-41ba-9fb5-fbb9bfbd08d3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.32.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.5.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (11.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjVxugbEPjCl",
        "outputId": "56399da5-2596-4e73-8c15-0077e0361796"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from groundingdino.util.inference import load_image, predict, annotate\n",
        "from groundingdino.util.utils import clean_state_dict\n",
        "from groundingdino.models import build_model\n",
        "from torchvision.ops import box_convert\n",
        "\n",
        "# Import SLConfig to resolve the issue\n",
        "from groundingdino.util.slconfig import SLConfig  # Add this import\n",
        "\n",
        "# Your model loading function\n",
        "def load_model_hf(ckpt_filename, config_file):\n",
        "    args = SLConfig.fromfile(config_file)  # This should now work with the import\n",
        "    model = build_model(args)\n",
        "    checkpoint = torch.load(ckpt_filename, map_location=\"cpu\")\n",
        "    state_dict = clean_state_dict(checkpoint[\"model\"])\n",
        "    filtered_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict()}\n",
        "    model.load_state_dict(filtered_state_dict, strict=False)\n",
        "    return model\n",
        "\n",
        "# Load model\n",
        "ckpt_filename = \"/content/weights/groundingdino_swint_ogc.pth\"\n",
        "ckpt_config_filename = \"/content/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
        "model = load_model_hf(ckpt_filename, ckpt_config_filename)\n",
        "\n",
        "# Prediction and annotation utilities\n",
        "def generate_masks_with_grounding(image_source, boxes):\n",
        "    h, w, _ = image_source.shape\n",
        "    boxes_unnorm = boxes * torch.Tensor([w, h, w, h])\n",
        "    boxes_xyxy = box_convert(boxes=boxes_unnorm, in_fmt=\"cxcywh\", out_fmt=\"xyxy\").numpy()\n",
        "    mask = np.zeros_like(image_source)\n",
        "    for box in boxes_xyxy:\n",
        "        x0, y0, x1, y1 = box\n",
        "        mask[int(y0):int(y1), int(x0):int(x1), :] = 255\n",
        "    return mask\n",
        "\n",
        "def get_highest_prob_boxes(logits, phrases, boxes):\n",
        "    phrase_to_data = {}\n",
        "    for i, phrase in enumerate(phrases):\n",
        "        if phrase not in phrase_to_data:\n",
        "            # Save the initial data for this phrase\n",
        "            phrase_to_data[phrase] = (logits[i], boxes[i], phrase)\n",
        "        else:\n",
        "            # Update if the current box has a higher probability\n",
        "            current_prob, _, _ = phrase_to_data[phrase]\n",
        "            if logits[i] > current_prob:\n",
        "                phrase_to_data[phrase] = (logits[i], boxes[i], phrase)\n",
        "\n",
        "    # Extract the data with the highest probability for each unique phrase\n",
        "    highest_prob_data = list(phrase_to_data.values())\n",
        "\n",
        "    # Separate into logits, boxes, and phrases\n",
        "    highest_logits = torch.tensor([item[0] for item in highest_prob_data])\n",
        "    highest_boxes = torch.stack([item[1] for item in highest_prob_data])\n",
        "    highest_phrases = [item[2] for item in highest_prob_data]\n",
        "\n",
        "    return highest_logits, highest_boxes, highest_phrases\n",
        "\n",
        "# List of text prompts for detection\n",
        "TEXT_PROMPTS = [\"turtle\"]\n",
        "\n",
        "# Set thresholds\n",
        "BOX_THRESHOLD = 0.35\n",
        "TEXT_THRESHOLD = 0.20\n",
        "\n",
        "# Load image\n",
        "image_source, image = load_image(\"/content/drive/MyDrive/inputimgs/scene_3_normal.png\")\n",
        "\n",
        "# Initialize lists to store aggregated results\n",
        "all_highest_logits = []\n",
        "all_highest_boxes = []\n",
        "all_highest_phrases = []\n",
        "\n",
        "# Loop through each text prompt and process predictions\n",
        "for prompt in TEXT_PROMPTS:\n",
        "    # Get predictions (bounding boxes and associated probabilities)\n",
        "    boxes, logits, phrases = predict(\n",
        "        model=model,\n",
        "        image=image,\n",
        "        caption=prompt,\n",
        "        box_threshold=BOX_THRESHOLD,\n",
        "        text_threshold=TEXT_THRESHOLD\n",
        "    )\n",
        "\n",
        "    # Print all detections for the current prompt\n",
        "    print(f\"All detections for prompt '{prompt}':\")\n",
        "    print(\"Phrases:\", phrases)\n",
        "    print(\"Logits:\", logits)\n",
        "    print(\"Boxes:\", boxes)\n",
        "\n",
        "    # Get highest probability boxes, logits, and phrases for the current prompt\n",
        "    highest_logits, highest_prob_boxes, highest_phrases = get_highest_prob_boxes(logits, phrases, boxes)\n",
        "\n",
        "    # Append results to the aggregated lists\n",
        "    all_highest_logits.append(highest_logits)\n",
        "    all_highest_boxes.append(highest_prob_boxes)\n",
        "    all_highest_phrases.extend(highest_phrases)\n",
        "\n",
        "# Concatenate all the results into single tensors/lists\n",
        "final_highest_logits = torch.cat(all_highest_logits, dim=0)\n",
        "final_highest_boxes = torch.cat(all_highest_boxes, dim=0)\n",
        "final_highest_phrases = all_highest_phrases\n",
        "\n",
        "# Annotate the image with predictions from all prompts\n",
        "annotated_frame = annotate(\n",
        "    image_source=image_source,\n",
        "    boxes=final_highest_boxes,\n",
        "    logits=final_highest_logits,\n",
        "    phrases=final_highest_phrases\n",
        ")\n",
        "annotated_frame = annotated_frame[..., ::-1]  # BGR to RGB\n",
        "Image.fromarray(annotated_frame).save(\"/content/drive/MyDrive/outputfolder/multi_prompt_annotatedv1.png\")\n",
        "\n",
        "# Generate masks using these highest probability boxes\n",
        "image_mask = generate_masks_with_grounding(image_source, final_highest_boxes)\n",
        "Image.fromarray(image_mask).save(\"/content/drive/MyDrive/outputfolder/multi_prompt_maskv1.png\")\n",
        "\n",
        "# Optionally, print the results for debugging\n",
        "print(\"Final Highest Probability Boxes:\", final_highest_boxes)\n",
        "print(\"Final Highest Probability Phrases:\", final_highest_phrases)\n",
        "print(\"Final Highest Probability Logits:\", final_highest_logits)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzXAiXL1Pwlv",
        "outputId": "4bc9e784-dcf7-4de1-ca01-6cb71118f077"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final text_encoder_type: bert-base-uncased\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All detections for prompt 'turtle':\n",
            "Phrases: ['turtle', 'turtle', 'turtle', 'turtle']\n",
            "Logits: tensor([0.7741, 0.6518, 0.6698, 0.4431])\n",
            "Boxes: tensor([[0.3980, 0.5451, 0.2629, 0.2611],\n",
            "        [0.5515, 0.4850, 0.1499, 0.1831],\n",
            "        [0.8208, 0.6568, 0.1583, 0.1798],\n",
            "        [0.5639, 0.8953, 0.1964, 0.1834]])\n",
            "Final Highest Probability Boxes: tensor([[0.3980, 0.5451, 0.2629, 0.2611]])\n",
            "Final Highest Probability Phrases: ['turtle']\n",
            "Final Highest Probability Logits: tensor([0.7741])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# Your data\n",
        "final_highest_boxes = torch.tensor([[0.4003, 0.5450, 0.2674, 0.2612]])\n",
        "final_highest_phrases = ['turtle']\n",
        "dialogues = {\n",
        "    \"turtle\": \"Let's see\"\n",
        "}\n",
        "\n",
        "# Load source image\n",
        "source_img_path = \"/content/drive/MyDrive/inputimgs/scene_3_normal.png\"  # Update this to your actual image path\n",
        "image = Image.open(source_img_path)\n",
        "w, h = image.size\n",
        "\n",
        "def draw_dialogue_bubbles(image, boxes, phrases, dialogues):\n",
        "    \"\"\"\n",
        "    Draw dialogue bubbles near bounding boxes with specified phrases.\n",
        "    \"\"\"\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    # Try to load a font; fallback to default PIL font if unavailable\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"arial.ttf\", 14)  # Update to your system font path if needed\n",
        "    except IOError:\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    for i, box in enumerate(boxes):\n",
        "        # Convert normalized box to pixel coordinates\n",
        "        x_center, y_center, box_width, box_height = box.numpy()\n",
        "        x_center *= w\n",
        "        y_center *= h\n",
        "        box_width *= w\n",
        "        box_height *= h\n",
        "\n",
        "        # Dialogue text\n",
        "        dialogue = dialogues.get(phrases[i], \"\")\n",
        "\n",
        "        # Bubble dimensions\n",
        "        bubble_width = 150\n",
        "        bubble_height = 50\n",
        "        padding = 10  # Padding inside the bubble for text\n",
        "\n",
        "        # Wrap text to fit inside the bubble width\n",
        "        wrapped_text = textwrap.fill(dialogue, width=int(bubble_width // (font.size * 0.6)))\n",
        "        lines = wrapped_text.split(\"\\n\")\n",
        "        line_height = font.size\n",
        "        bubble_height = max(bubble_height, len(lines) * line_height + padding * 2)\n",
        "\n",
        "        # Determine bubble position\n",
        "        bubble_x = x_center\n",
        "        bubble_y = y_center - box_height / 2 - bubble_height - 10  # Default above the box\n",
        "\n",
        "        # Adjust bubble position if it goes out of bounds\n",
        "        if bubble_y < 0:  # If at top edge, place below or to the side\n",
        "            bubble_y = y_center + box_height / 2 + 10\n",
        "\n",
        "        # Define bubble bounds\n",
        "        bubble_bounds = [\n",
        "            bubble_x - bubble_width / 2,\n",
        "            bubble_y - bubble_height,\n",
        "            bubble_x + bubble_width / 2,\n",
        "            bubble_y\n",
        "        ]\n",
        "\n",
        "        # Draw the bubble (ellipse)\n",
        "        draw.ellipse(bubble_bounds, fill=(255, 255, 255), outline=(0, 0, 0), width=2)\n",
        "\n",
        "        # Number of tail circles to create more connection between the bubble and the character\n",
        "        tail_segments = 3\n",
        "        tail_radius = 5\n",
        "        tail_spacing = 18  # Spacing between each circle in the tail\n",
        "\n",
        "        # Draw multiple small circles for the tail\n",
        "        for j in range(tail_segments):\n",
        "            tail_x = x_center\n",
        "            tail_y = y_center - box_height / 2 - (j + 1) * tail_spacing\n",
        "            draw.ellipse(\n",
        "                [tail_x - tail_radius, tail_y - tail_radius,\n",
        "                 tail_x + tail_radius, tail_y + tail_radius],\n",
        "                fill=(255, 255, 255), outline=(0, 0, 0), width=2\n",
        "            )\n",
        "\n",
        "        # Center the text inside the bubble\n",
        "        total_text_height = len(lines) * line_height\n",
        "        text_start_y = bubble_y - bubble_height + (bubble_height - total_text_height) / 2\n",
        "\n",
        "        for line in lines:\n",
        "            text_width = draw.textlength(line, font=font)\n",
        "            text_start_x = bubble_x - text_width / 2\n",
        "            draw.text((text_start_x, text_start_y), line, fill=(0, 0, 0), font=font)\n",
        "            text_start_y += line_height  # Move to the next line\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "\n",
        "image_with_bubbles = draw_dialogue_bubbles(image, final_highest_boxes, final_highest_phrases, dialogues)\n",
        "\n",
        "# Save the result\n",
        "output_path = \"/content/drive/MyDrive/outputfolder/scene_3_normal.png_final.jpg\"  # Update this to your desired output path\n",
        "image_with_bubbles.save(output_path)\n",
        "\n",
        "print(f\"Annotated image saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIc5GpwaRrOo",
        "outputId": "50b3d5e5-c207-498f-b52f-dd315e6a532f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotated image saved to /content/drive/MyDrive/outputfolder/scene_3_normal.png_final.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# Load the base image (the main image)\n",
        "base_image = Image.open(\"/content/drive/MyDrive/inputimgs/scene_1_normal.png\")\n",
        "\n",
        "# Load the overlay image\n",
        "overlay_image = Image.open(\"/content/drive/MyDrive/outputfolder/upperleft.png\")\n",
        "\n",
        "# Resize the overlay image (optional, if needed)\n",
        "overlay_image = overlay_image.resize((100, 100))  # Adjust size as required\n",
        "\n",
        "# Paste the overlay image onto the base image at the upper-left corner\n",
        "base_image.paste(overlay_image, (0, 0), overlay_image)  # Use the third argument for transparency\n",
        "\n",
        "# Draw text on the overlay image area\n",
        "draw = ImageDraw.Draw(base_image)\n",
        "\n",
        "# Set the font (adjust path or use a default font)\n",
        "try:\n",
        "    font = ImageFont.truetype(\"arial.ttf\", 20)  # Adjust font size\n",
        "except IOError:\n",
        "    font = ImageFont.load_default()  # Fallback to default font\n",
        "\n",
        "# Add text on the upper-left overlay area\n",
        "text = \"Hello!\"\n",
        "text_position = (10, 10)  # Position text slightly away from the top-left corner\n",
        "text_color = (0,0,0)  # White color\n",
        "draw.text(text_position, text, fill=text_color, font=font)\n",
        "\n",
        "# Save the final image\n",
        "base_image.save(\"/content/drive/MyDrive/captionoutput/output_image.jpg\")\n",
        "\n",
        "print(\"Image saved with overlay and text as output_image.jpg\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH990BRnhfL8",
        "outputId": "86cdc640-3da6-4a2a-edf8-37b218bbe459"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image saved with overlay and text as output_image.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "def convert_boxes_to_pixel_coordinates(boxes, image_size):\n",
        "    \"\"\"\n",
        "    Convert normalized boxes to pixel coordinates.\n",
        "    \"\"\"\n",
        "    pixel_boxes = []\n",
        "    for box in boxes:\n",
        "        x_center, y_center, width, height = box\n",
        "        x_center_pixel = x_center * image_size[0]\n",
        "        y_center_pixel = y_center * image_size[1]\n",
        "        box_width_pixel = width * image_size[0]\n",
        "        box_height_pixel = height * image_size[1]\n",
        "\n",
        "        x_min = x_center_pixel - box_width_pixel / 2\n",
        "        y_min = y_center_pixel - box_height_pixel / 2\n",
        "        x_max = x_center_pixel + box_width_pixel / 2\n",
        "        y_max = y_center_pixel + box_height_pixel / 2\n",
        "\n",
        "        pixel_boxes.append([x_min, y_min, x_max, y_max])\n",
        "\n",
        "    return pixel_boxes\n",
        "\n",
        "def wrap_text(text, font, max_width):\n",
        "    \"\"\"\n",
        "    Wrap text to fit within a specified width.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    current_line = words[0]\n",
        "\n",
        "    for word in words[1:]:\n",
        "        if font.getsize(current_line + \" \" + word)[0] <= max_width:\n",
        "            current_line += \" \" + word\n",
        "        else:\n",
        "            lines.append(current_line)\n",
        "            current_line = word\n",
        "\n",
        "    lines.append(current_line)\n",
        "    return lines\n",
        "\n",
        "\n",
        "def get_text_size(text, font):\n",
        "    \"\"\"\n",
        "    Get the width and height of the text using textbbox.\n",
        "    \"\"\"\n",
        "    im = Image.new(mode=\"P\", size=(0, 0))\n",
        "    draw = ImageDraw.Draw(im)\n",
        "    bbox = draw.textbbox((0, 0), text, font=font)\n",
        "    width, height = bbox[2] - bbox[0], bbox[3] - bbox[1]\n",
        "    return width, height\n",
        "\n",
        "\n",
        "def resize_callout_image(callout_img, text, base_size=(150, 150), padding=10):\n",
        "    \"\"\"\n",
        "    Resize callout image to fit text and wrap text if necessary.\n",
        "    \"\"\"\n",
        "    # Use default font from Pillow\n",
        "    font = ImageFont.load_default()\n",
        "    base_width, base_height = base_size\n",
        "\n",
        "    # Create an image to calculate text dimensions\n",
        "    lines = wrap_text(text, font, base_width - 2 * padding)\n",
        "    pil_image = Image.fromarray(callout_img)\n",
        "    draw = ImageDraw.Draw(pil_image)\n",
        "\n",
        "    # Get text height by checking all lines\n",
        "    text_height = sum(get_text_size(line, font)[1] for line in lines)\n",
        "\n",
        "    # Resize if necessary\n",
        "    total_height = max(base_height, text_height + 2 * padding)\n",
        "    resized_callout = cv2.resize(callout_img, (base_width, total_height))\n",
        "\n",
        "    # Draw text onto the resized callout\n",
        "    pil_image = Image.fromarray(resized_callout)\n",
        "    draw = ImageDraw.Draw(pil_image)\n",
        "\n",
        "    y = padding\n",
        "    for line in lines:\n",
        "        text_width, text_height = get_text_size(line, font)\n",
        "        x = (base_width - text_width) // 2\n",
        "        draw.text((x, y), line, fill=\"black\", font=font)\n",
        "        y += text_height\n",
        "\n",
        "    return np.array(pil_image)\n",
        "\n",
        "\n",
        "def place_callouts(turtle_boxes, logits, phrases, callout_images, image_size):\n",
        "    \"\"\"\n",
        "    Place callouts near detected turtles based on logits and avoid overlaps.\n",
        "    \"\"\"\n",
        "    # Convert normalized boxes to pixel coordinates\n",
        "    pixel_boxes = convert_boxes_to_pixel_coordinates(turtle_boxes, image_size)\n",
        "\n",
        "    sorted_indices = sorted(range(len(logits)), key=lambda i: logits[i], reverse=True)\n",
        "    directions = [(1, 1), (-1, 1), (1, -1), (-1, -1)]  # Top-right, Top-left, Bottom-right, Bottom-left\n",
        "    callout_positions = []\n",
        "    placed_callouts = []\n",
        "\n",
        "    for idx in sorted_indices:\n",
        "        box = pixel_boxes[idx]\n",
        "        x_center = (box[0] + box[2]) / 2\n",
        "        y_center = (box[1] + box[3]) / 2\n",
        "        box_width = box[2] - box[0]\n",
        "        box_height = box[3] - box[1]\n",
        "\n",
        "        callout_img = callout_images[idx % len(callout_images)]  # Cycle through callout images\n",
        "        text = phrases[idx]\n",
        "\n",
        "        placed = False\n",
        "        for dx, dy in directions:\n",
        "            callout_x = int(x_center + dx * box_width)\n",
        "            callout_y = int(y_center + dy * box_height)\n",
        "\n",
        "            # Ensure callout fits within the image boundaries\n",
        "            if (0 <= callout_x <= image_size[0] - 150 and\n",
        "                0 <= callout_y <= image_size[1] - 150):\n",
        "\n",
        "                # Check for overlaps with already placed callouts\n",
        "                collision = False\n",
        "                for placed_x, placed_y in callout_positions:\n",
        "                    if (abs(placed_x - callout_x) < 150 and\n",
        "                        abs(placed_y - callout_y) < 150):\n",
        "                        collision = True\n",
        "                        break\n",
        "\n",
        "                if not collision:\n",
        "                    # Resize and draw callout\n",
        "                    resized_callout = resize_callout_image(callout_img, text)\n",
        "                    placed_callouts.append((resized_callout, (callout_x, callout_y)))\n",
        "                    callout_positions.append((callout_x, callout_y))\n",
        "                    placed = True\n",
        "                    break\n",
        "\n",
        "        if not placed:\n",
        "            print(f\"Could not place callout for turtle with logits {logits[idx]} at {box}\")\n",
        "\n",
        "    return placed_callouts\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Inputs\n",
        "    image_size = (1024, 1024)  # Example image size\n",
        "    turtle_boxes = [\n",
        "        [0.3980, 0.5451, 0.2629, 0.2611],\n",
        "        [0.5515, 0.4850, 0.1499, 0.1831],\n",
        "        [0.8208, 0.6568, 0.1583, 0.1798],\n",
        "        [0.5639, 0.8953, 0.1964, 0.1834]\n",
        "    ]\n",
        "    logits = [0.7741, 0.6518, 0.6698, 0.4431]\n",
        "    phrases = ['turtle', 'turtle', 'turtle', 'turtle']\n",
        "\n",
        "    # Load example callout images (replace with actual file paths)\n",
        "    callout_image_paths = ['/content/drive/MyDrive/outputfolder/upperleft.png', '/content/drive/MyDrive/outputfolder/upperright.png', '/content/drive/MyDrive/outputfolder/downside_rotated_image.png', '/content/drive/MyDrive/outputfolder/uppermiddle.png']\n",
        "    callout_images = [cv2.imread(path) for path in callout_image_paths]\n",
        "\n",
        "    # Place callouts\n",
        "    placed_callouts = place_callouts(turtle_boxes, logits, phrases, callout_images, image_size)\n",
        "\n",
        "    # Visualize results (example visualization)\n",
        "    for callout, position in placed_callouts:\n",
        "        print(f\"Callout placed at: {position}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkpC51QSv9N-",
        "outputId": "0c9d01e9-cf20-4d0a-b799-44b6e65df470"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not place callout for turtle with logits 0.4431 at [476.87679999999995, 822.8864, 677.9903999999999, 1010.688]\n",
            "Callout placed at: (676, 825)\n",
            "Callout placed at: (678, 488)\n",
            "Callout placed at: (411, 684)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r3hFvrO7ylmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import torch\n",
        "\n",
        "# Normalize boxes to pixel coordinates\n",
        "def normalize_boxes(boxes, img_shape):\n",
        "    h, w = img_shape  # Unpack height and width\n",
        "    normalized_boxes = []\n",
        "    for box in boxes:\n",
        "        # Unpack normalized box\n",
        "        x_center, y_center, box_width, box_height = box.numpy()\n",
        "\n",
        "        # Convert to pixel coordinates\n",
        "        x_center *= w\n",
        "        y_center *= h\n",
        "        box_width *= w\n",
        "        box_height *= h\n",
        "\n",
        "        # Calculate top-left and bottom-right coordinates\n",
        "        x0 = x_center - (box_width / 2)\n",
        "        y0 = y_center - (box_height / 2)\n",
        "        x1 = x_center + (box_width / 2)\n",
        "        y1 = y_center + (box_height / 2)\n",
        "\n",
        "        # Append the pixel coordinates\n",
        "        normalized_boxes.append([x0, y0, x1, y1])\n",
        "\n",
        "    return np.array(normalized_boxes)\n",
        "\n",
        "# Check for overlaps\n",
        "def check_overlap(box1, boxes):\n",
        "    x1, y1, x2, y2 = box1\n",
        "    for box in boxes:\n",
        "        bx1, by1, bx2, by2 = box\n",
        "        if not (x2 < bx1 or x1 > bx2 or y2 < by1 or y1 > by2):  # Overlapping condition\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Place callout image\n",
        "def place_callout(base_image, box, other_boxes, callout_images, text, font_path):\n",
        "    positions = [\n",
        "        \"Top-right\", \"Top-middle\", \"Top-left\",\n",
        "        \"Bottom-right\", \"Bottom-middle\", \"Bottom-left\"\n",
        "    ]\n",
        "    h, w, _ = base_image.shape\n",
        "    box_x0, box_y0, box_x1, box_y1 = box\n",
        "    box_center_x = int((box_x0 + box_x1) / 2)\n",
        "    box_center_y = int((box_y0 + box_y1) / 2)\n",
        "\n",
        "    # Define placement offsets for each position\n",
        "    offsets = [\n",
        "        (box_x1 + 10, box_y0 - 50),  # Top-right\n",
        "        (box_center_x - 50, box_y0 - 50),  # Top-middle\n",
        "        (box_x0 - 110, box_y0 - 50),  # Top-left\n",
        "        (box_x1 + 10, box_y1 + 10),  # Bottom-right\n",
        "        (box_center_x - 50, box_y1 + 10),  # Bottom-middle\n",
        "        (box_x0 - 110, box_y1 + 10),  # Bottom-left\n",
        "    ]\n",
        "\n",
        "    for idx, (pos, offset) in enumerate(zip(positions, offsets)):\n",
        "        # Resize callout image to 150x150\n",
        "        callout_img = callout_images[pos]\n",
        "        callout_img = cv2.resize(callout_img, (150, 150))  # Resize to 150x150\n",
        "        x_offset, y_offset = offset\n",
        "        callout_h, callout_w, _ = callout_img.shape\n",
        "\n",
        "        # Ensure offsets are integers\n",
        "        x_offset = int(x_offset)\n",
        "        y_offset = int(y_offset)\n",
        "\n",
        "        # Debugging: Print coordinates where callout image is being placed\n",
        "        print(f\"Trying to place callout at: x_offset={x_offset}, y_offset={y_offset}\")\n",
        "        print(f\"Callout size: width={callout_w}, height={callout_h}\")\n",
        "\n",
        "        # Check if the callout image fits within the base image boundaries\n",
        "        if x_offset + callout_w > w or y_offset + callout_h > h or x_offset < 0 or y_offset < 0:\n",
        "            print(\"Callout exceeds image boundaries, skipping this position.\")\n",
        "            continue\n",
        "\n",
        "        # Check for overlaps\n",
        "        if not check_overlap([x_offset, y_offset, x_offset + callout_w, y_offset + callout_h], other_boxes):\n",
        "            # Resize callout image dynamically for text\n",
        "            text_lines = text.split(\" \")\n",
        "            max_line_length = 15\n",
        "            resized_text = \"\\n\".join(\n",
        "                [\" \".join(text_lines[i:i + max_line_length]) for i in range(0, len(text_lines), max_line_length)]\n",
        "            )\n",
        "\n",
        "            # Draw text on the callout image\n",
        "            pil_callout = Image.fromarray(callout_img)\n",
        "            draw = ImageDraw.Draw(pil_callout)\n",
        "            font = ImageFont.load_default()  # No need for a font path\n",
        "\n",
        "            # Use textbbox to get text dimensions\n",
        "            _, _, text_width, text_height = draw.textbbox((0, 0), resized_text, font=font)\n",
        "            new_width = max(callout_img.shape[1], text_width + 20)\n",
        "            new_height = callout_img.shape[0] + text_height + 20\n",
        "            pil_callout = pil_callout.resize((int(new_width), int(new_height)))\n",
        "            draw = ImageDraw.Draw(pil_callout)\n",
        "            draw.text((10, 10), resized_text, fill=\"black\", font=font)\n",
        "\n",
        "            # Overlay callout on the base image\n",
        "            new_height = int(new_height)\n",
        "            new_width = int(new_width)\n",
        "            base_image[y_offset:y_offset + new_height, x_offset:x_offset + new_width] = np.array(pil_callout)\n",
        "            print(f\"Callout placed at: x_offset={x_offset}, y_offset={y_offset}\")\n",
        "            return base_image  # Exit after placing the first valid callout\n",
        "\n",
        "    print(\"No valid placement found for callout.\")\n",
        "    return base_image  # Return original image if no placement is found\n",
        "\n",
        "# Main function\n",
        "def annotate_with_callouts(image_path, boxes, logits, callout_texts, callout_images, output_path, font_path):\n",
        "    # Open the image using PIL to get its dimensions\n",
        "    pil_image = Image.open(image_path)\n",
        "    w, h = pil_image.size  # Image width and height\n",
        "    base_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Normalize boxes to pixel coordinates\n",
        "    normalized_boxes = normalize_boxes(boxes, (h, w))\n",
        "    sorted_indices = torch.argsort(logits, descending=True)\n",
        "\n",
        "    # Place callouts based on sorted probabilities\n",
        "    for idx in sorted_indices:\n",
        "        box = normalized_boxes[idx]\n",
        "        text = callout_texts[idx]\n",
        "        base_image = place_callout(base_image, box, normalized_boxes, callout_images, text, font_path)\n",
        "\n",
        "    # Save the final annotated image\n",
        "    cv2.imwrite(output_path, base_image)\n",
        "    print(f\"Annotated image saved at {output_path}\")\n",
        "\n",
        "# Example Usage\n",
        "image_path = \"/content/drive/MyDrive/inputimgs/scene_3_normal.png\"\n",
        "output_path = \"/content/drive/MyDrive/captionoutput/scene_3_annoted_withcallout.png\"\n",
        "\n",
        "callout_images = {\n",
        "    \"Top-right\": cv2.imread(\"/content/drive/MyDrive/callout_imgs/upperright.png\"),\n",
        "    \"Top-middle\": cv2.imread(\"/content/drive/MyDrive/callout_imgs/uppermiddle.png\"),\n",
        "    \"Top-left\": cv2.imread(\"/content/drive/MyDrive/callout_imgs/upperleft.png\"),\n",
        "    \"Bottom-right\": cv2.imread(\"/content/drive/MyDrive/callout_imgs/downright.png\"),\n",
        "    \"Bottom-middle\": cv2.imread(\"/content/drive/MyDrive/callout_imgs/downmiddle.png\"),\n",
        "    \"Bottom-left\": cv2.imread(\"/content/drive/MyDrive/callout_imgs/downleft.png\"),\n",
        "}\n",
        "\n",
        "boxes = torch.tensor([\n",
        "    [0.3980, 0.5451, 0.2629, 0.2611],\n",
        "    [0.5515, 0.4850, 0.1499, 0.1831],\n",
        "    [0.8208, 0.6568, 0.1583, 0.1798],\n",
        "    [0.5639, 0.8953, 0.1964, 0.1834]\n",
        "])\n",
        "logits = torch.tensor([0.7741, 0.6518, 0.6698, 0.4431])\n",
        "callout_texts = [\"Let's wait and watch\"] * len(boxes)\n",
        "\n",
        "annotate_with_callouts(image_path, boxes, logits, callout_texts, callout_images, output_path, None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tpra7zsk9zvk",
        "outputId": "410ba8f6-c6c3-41cd-f2b8-716ab65be5e6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying to place callout at: x_offset=552, y_offset=374\n",
            "Callout size: width=150, height=150\n",
            "Trying to place callout at: x_offset=357, y_offset=374\n",
            "Callout size: width=150, height=150\n",
            "Trying to place callout at: x_offset=162, y_offset=374\n",
            "Callout size: width=150, height=150\n",
            "Trying to place callout at: x_offset=552, y_offset=701\n",
            "Callout size: width=150, height=150\n",
            "Trying to place callout at: x_offset=357, y_offset=701\n",
            "Callout size: width=150, height=150\n",
            "Trying to place callout at: x_offset=162, y_offset=701\n",
            "Callout size: width=150, height=150\n",
            "Callout placed at: x_offset=162, y_offset=701\n",
            "Trying to place callout at: x_offset=931, y_offset=530\n",
            "Callout size: width=150, height=150\n",
            "Callout exceeds image boundaries, skipping this position.\n",
            "Trying to place callout at: x_offset=790, y_offset=530\n",
            "Callout size: width=150, height=150\n",
            "Trying to place callout at: x_offset=649, y_offset=530\n",
            "Callout size: width=150, height=150\n",
            "Trying to place callout at: x_offset=931, y_offset=774\n",
            "Callout size: width=150, height=150\n",
            "Callout exceeds image boundaries, skipping this position.\n",
            "Trying to place callout at: x_offset=790, y_offset=774\n",
            "Callout size: width=150, height=150\n",
            "Callout placed at: x_offset=790, y_offset=774\n",
            "Trying to place callout at: x_offset=651, y_offset=352\n",
            "Callout size: width=150, height=150\n",
            "Callout placed at: x_offset=651, y_offset=352\n",
            "Trying to place callout at: x_offset=687, y_offset=772\n",
            "Callout size: width=150, height=150\n",
            "Callout placed at: x_offset=687, y_offset=772\n",
            "Annotated image saved at /content/drive/MyDrive/captionoutput/scene_3_annoted_withcallout.png\n"
          ]
        }
      ]
    }
  ]
}